 {
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff02e77-ce1c-4b99-b3dd-c8ed2db1ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4a3e22-58e8-4953-8abf-24bfd9791e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.dataset import Conversation\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from pydantic import BaseModel\n",
    "import numpy as np\n",
    "import logging\n",
    "from typing import List\n",
    "import os\n",
    "from helpers.fair_forge import FairForge\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80672b81-e63c-417f-93d6-3933a4c9fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "ELASTIC_URL = os.environ.get('ELASTIC_URL')\n",
    "ELASTIC_AUTH = [os.environ.get('ELASTIC_AUTH_USER'), os.environ.get('ELASTIC_AUTH_PASSWORD')]\n",
    "dataset = os.environ.get(\"dataset\", \"asb\")\n",
    "humanity_index = f\"{dataset}-humanity\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e3184e-089a-4fa8-89fc-257e2619eb82",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Implement Emotion matching\n",
    "- Implement Language Style Matching, LSM\n",
    "- Implement Agreeableness\n",
    "- Implement Empathy, Empathic Concern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec06d83-c1db-4fb3-89a3-973dce2ff804",
   "metadata": {},
   "source": [
    "## Emotional entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4388c3d-0d92-405b-91af-53d374f32881",
   "metadata": {},
   "source": [
    "Based on NRC emotional lexicon and Plutchik eight basic emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e29d3-7ff2-4f01-bb2e-a488a2e79c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_columns = ['Anger', 'Anticipation', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise', 'Trust']\n",
    "\n",
    "def load_emotion_lexicon(language: str):\n",
    "    nrc = pd.read_csv(\"artifacts/lexicon.csv\",sep=';')\n",
    "    lexicon = {}\n",
    "    for index, row in nrc.iterrows():\n",
    "        word = str(row[language]).lower()\n",
    "        emotions = [e for e in emotion_columns if row[e]==1]\n",
    "        lexicon[word] = emotions\n",
    "    return lexicon\n",
    "    \n",
    "def tokenize(text):\n",
    "    return re.findall(r'\\b\\w+\\b', text.lower())\n",
    "\n",
    "def get_emotion_distribution(text, lexicon, emotion_list):\n",
    "    counts = defaultdict(int) ## Creates a  dictionary that if no index found returns 0 \n",
    "    total = 0\n",
    "    for word in tokenize(text):\n",
    "        if word in lexicon:\n",
    "            for emotion in lexicon[word]:\n",
    "                counts[emotion] += 1\n",
    "                total += 1\n",
    "\n",
    "    if total == 0:\n",
    "        return {emotion: 0 for emotion in emotion_list}\n",
    "\n",
    "    return {emotion: counts[emotion] / total for emotion in emotion_list} #frequency / total\n",
    "\n",
    "def emotional_entropy(distribution): #entropy\n",
    "    entropy = 0\n",
    "    for p in distribution.values():\n",
    "        if p > 0:\n",
    "            entropy -= p * math.log2(p)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3b8c4-5dd6-4a28-b1be-06ee5de7e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanityBatch(BaseModel):\n",
    "    session_id: str\n",
    "    humanity_assistant_emotional_entropy: float\n",
    "    humanity_ground_truth_spearman: float\n",
    "    humanity_assistant_anger: float\n",
    "    humanity_assistant_anticipation: float\n",
    "    humanity_assistant_disgust: float\n",
    "    humanity_assistant_fear: float\n",
    "    humanity_assistant_joy: float\n",
    "    humanity_assistant_sadness: float\n",
    "    humanity_assistant_surprise: float\n",
    "    humanity_assistant_trust: float\n",
    "    qa_id: str\n",
    "    assistant_id: str\n",
    "\n",
    "class HumanityMetric(BaseModel):\n",
    "    session_id: str\n",
    "    conv_thread: List[HumanityBatch] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f0cd6d-be23-4a3b-8eb6-3351e72125dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_index(index_name: str, mapping: dict):\n",
    "    if es.indices.exists(index=index_name):\n",
    "        es.indices.delete(index=index_name)\n",
    "        print(f\"Index '{index_name}' deleted.\")\n",
    "    es.indices.create(index=index_name, body=mapping)\n",
    "    print(f\"Index '{index_name}' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d34a60-b798-45a4-8f1b-51420cb7a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\n",
    "    ELASTIC_URL,\n",
    "    basic_auth=tuple(ELASTIC_AUTH),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754d6b0-11dd-4b09-987a-dceae5014f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanityAnalyzer(FairForge):\n",
    "    def process(self, thread: Conversation):\n",
    "        for batch in thread.conversation:\n",
    "            query = batch.question\n",
    "            lexicon = load_emotion_lexicon(thread.preferred_language)\n",
    "            # Get emotional distribution for ground truth and real assistant\n",
    "            assistant_distribution = get_emotion_distribution(batch.assistant, lexicon, emotion_columns)\n",
    "            generated_vec = [assistant_distribution[e] for e in emotion_columns]\n",
    "            ## Execute emotional entropy\n",
    "            ent = emotional_entropy(assistant_distribution)\n",
    "            if batch.ground_truth_assistant is None:\n",
    "                spearman_val = 0\n",
    "            else:\n",
    "                ground_truth_assistant_distribution = get_emotion_distribution(batch.ground_truth_assistant, lexicon, emotion_columns)\n",
    "                ## Spearman correlation between ground truth and real assistant answer\n",
    "                expected_vec = [ground_truth_assistant_distribution[e] for e in emotion_columns]\n",
    "                logging.info(f\"Query: {query}\")\n",
    "                \n",
    "                if np.std(generated_vec) == 0 or np.std(expected_vec) == 0:\n",
    "                    logging.error(\"Spearman undefined due to constant vector.\")\n",
    "                    spearman_val = 0\n",
    "                else:\n",
    "                    spearman_val, _ = spearmanr(expected_vec, generated_vec)\n",
    "                    \n",
    "            logging.info(f\"Spearman value: {round(spearman_val, 3)}\")\n",
    "            batch = HumanityBatch(\n",
    "                humanity_assistant_emotional_entropy=ent,\n",
    "                humanity_ground_truth_spearman=round(spearman_val, 3),\n",
    "                session_id=thread.session_id,\n",
    "                qa_id=batch.qa_id,\n",
    "                assistant_id=thread.assistant_id,\n",
    "                **{f\"humanity_assistant_{key.lower()}\":assistant_distribution[key] for key in emotion_columns}\n",
    "            )\n",
    "            self.metrics.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780f2af2-130f-4974-b0f5-ea35fc776de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "humanity = HumanityAnalyzer()\n",
    "metrics = humanity.pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf13f41-55bd-4b38-93dc-7e18bab6a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_humanity = {\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"session_id\": {\"type\": \"keyword\"},\n",
    "      \"humanity_assistant_emotional_entropy\": {\"type\": \"float\"},\n",
    "      \"humanity_ground_truth_spearman\": {\"type\": \"float\"},\n",
    "      \"humanity_assistant_anger\": {\"type\": \"float\"},\n",
    "      \"humanity_assistant_anticipation\": {\"type\": \"float\"},\n",
    "      \"humanity_assistant_disgust\": {\"type\": \"float\"},\n",
    "      \"humanity_assistant_fear\": {\"type\": \"float\"},\n",
    "      \"humanity_assistant_joy\": {\"type\": \"float\"},\n",
    "      \"humanity_assistant_sadness\": {\"type\": \"float\"},\n",
    "      \"humanity_assistant_surprise\": {\"type\": \"float\"},\n",
    "      \"humanity_assistant_trust\": {\"type\": \"float\"},\n",
    "      \"assistant_id\": {\"type\": \"keyword\"},\n",
    "      \"qa_id\": {\"type\": \"keyword\"},\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
