{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa9f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --force-reinstall ../dist/alquimia_fair_forge-0.0.1.tar.gz -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef14db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fair_forge.metrics import BestOf\n",
    "from pydantic import SecretStr\n",
    "from helpers.retriever import LocalRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e850f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "judge_api_key = SecretStr(getpass(\"Please enter your Judge API key: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b364850",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = BestOf.run(\n",
    "    LocalRetriever,\n",
    "    judge_api_key=judge_api_key,\n",
    "    judge_model=\"llama-3.3-70b-versatile\",\n",
    "    verbose=False,\n",
    "    criteria=\"Decide which assistant is more helpful and accurate if I want a high level of emotions in the response\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c74a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_bestof_metric_simple(metric):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"{'BEST OF TOURNAMENT RESULTS':^80}\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Session ID: {metric.session_id}\")\n",
    "    print(f\"Winner: {metric.bestof_winner_id}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Tournament bracket\n",
    "    print(f\"\\n{'TOURNAMENT BRACKET':^80}\")\n",
    "    print(\"-\"*80)\n",
    "    for contest in metric.bestof_contests:\n",
    "        left_mark = \"‚úì\" if contest.winner_id == contest.left_id else \"‚úó\"\n",
    "        right_mark = \"‚úì\" if contest.winner_id == contest.right_id else \"‚úó\"\n",
    "        \n",
    "        print(f\"\\nRound {contest.round}:\")\n",
    "        print(f\"  [{left_mark}] {contest.left_id}\")\n",
    "        print(f\"  [{right_mark}] {contest.right_id}\")\n",
    "        print(f\"  ‚Üí Winner: {contest.winner_id} (Confidence: {contest.confidence*100:.0f}%)\")\n",
    "    \n",
    "    # Detailed rounds\n",
    "    print(f\"\\n\\n{'DETAILED ANALYSIS':^80}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for contest in metric.bestof_contests:\n",
    "        print(f\"\\n{'‚îÄ'*80}\")\n",
    "        print(f\"ROUND {contest.round}: {contest.left_id} vs {contest.right_id}\")\n",
    "        print(f\"{'‚îÄ'*80}\")\n",
    "        print(f\"Winner: {contest.winner_id}\")\n",
    "        print(f\"Confidence: {contest.confidence*100:.0f}%\")\n",
    "        \n",
    "        print(f\"\\nüìù VERDICT:\")\n",
    "        print(f\"   {contest.verdict}\\n\")\n",
    "        \n",
    "        reasoning = contest.reasoning\n",
    "        \n",
    "        # Left contestant\n",
    "        print(f\"\\n{contest.left_id.upper()}:\")\n",
    "        print(f\"  ‚úÖ Strengths:\")\n",
    "        for s in reasoning.get(f'{contest.left_id}_strengths', []):\n",
    "            print(f\"     ‚Ä¢ {s}\")\n",
    "        print(f\"  ‚ö†Ô∏è  Weaknesses:\")\n",
    "        for w in reasoning.get(f'{contest.left_id}_weaknesses', []):\n",
    "            print(f\"     ‚Ä¢ {w}\")\n",
    "        \n",
    "        # Right contestant\n",
    "        print(f\"\\n{contest.right_id.upper()}:\")\n",
    "        print(f\"  ‚úÖ Strengths:\")\n",
    "        for s in reasoning.get(f'{contest.right_id}_strengths', []):\n",
    "            print(f\"     ‚Ä¢ {s}\")\n",
    "        print(f\"  ‚ö†Ô∏è  Weaknesses:\")\n",
    "        for w in reasoning.get(f'{contest.right_id}_weaknesses', []):\n",
    "            print(f\"     ‚Ä¢ {w}\")\n",
    "    \n",
    "    # Final winner summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"{'üèÜ CHAMPION: ' + metric.bestof_winner_id + ' üèÜ':^80}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Aggregate strengths and weaknesses from all rounds where winner participated\n",
    "    all_strengths = []\n",
    "    all_weaknesses = []\n",
    "    final_verdicts = []\n",
    "    \n",
    "    for contest in metric.bestof_contests:\n",
    "        if contest.winner_id == metric.bestof_winner_id:\n",
    "            reasoning = contest.reasoning\n",
    "            strengths_key = f'{metric.bestof_winner_id}_strengths'\n",
    "            weaknesses_key = f'{metric.bestof_winner_id}_weaknesses'\n",
    "            \n",
    "            all_strengths.extend(reasoning.get(strengths_key, []))\n",
    "            all_weaknesses.extend(reasoning.get(weaknesses_key, []))\n",
    "            final_verdicts.append(contest.verdict)\n",
    "    \n",
    "    print(f\"\\n{'WHY ' + metric.bestof_winner_id.upper() + ' WON':^80}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    if final_verdicts:\n",
    "        print(\"\\nüìã Key Verdicts:\")\n",
    "        for i, verdict in enumerate(final_verdicts, 1):\n",
    "            print(f\"\\n  Round {i}:\")\n",
    "            print(f\"  {verdict}\")\n",
    "    \n",
    "    if all_strengths:\n",
    "        print(f\"\\n‚úÖ Overall Strengths:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b045760",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_bestof_metric_simple(metrics[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
