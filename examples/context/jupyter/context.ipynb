{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Metric Example\n",
    "\n",
    "This notebook demonstrates how to use the **Context** metric from Fair Forge to evaluate how well AI assistant responses align with the provided context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First, install Fair Forge and the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "!pip install \"alquimia-fair-forge[context]\" langchain-groq -q"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import the required modules and configure your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexfiorenza/.pyenv/versions/3.11.5/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "PyTorch was not found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add examples directory to path for helpers import\n",
    "sys.path.insert(0, str(Path(\"../..\").resolve()))\n",
    "\n",
    "from helpers.retriever import LocalRetriever\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from fair_forge.metrics.context import Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "GROQ_API_KEY = getpass.getpass(\"Enter your Groq API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Judge Model\n",
    "\n",
    "The Context metric uses an LLM as a judge to evaluate responses. You can use any LangChain-compatible chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_model = ChatGroq(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    api_key=GROQ_API_KEY,\n",
    "    temperature=0.0,\n",
    "    reasoning_format=\"parsed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Context Metric\n",
    "\n",
    "The Context metric evaluates each Q&A interaction in your dataset, scoring how well the assistant's response aligns with the provided context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 09:52:35,239 - fair_forge.utils.logging - INFO - Loaded dataset with 1 batches\n",
      "2026-01-28 09:52:35,240 - fair_forge.utils.logging - INFO - Starting to process dataset\n",
      "2026-01-28 09:52:35,241 - fair_forge.utils.logging - INFO - Session ID: 123, Assistant ID: my_assistant\n",
      "2026-01-28 09:52:35,241 - fair_forge.utils.logging - DEBUG - QA ID: 123\n",
      "2026-01-28 09:52:38,375 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-28 09:52:38,379 - fair_forge.utils.logging - DEBUG - Context insight: The assistant's response repeats a generic statement that Alquimia AI is a startup constructing assistants, which does not reflect the detailed, enterprise-grade, human-centered platform described in the context. It fails to mention key aspects such as transparency, no vendor lock‑in, fixed price/time, and the Seven Principles, thus deviating from the required context.\n",
      "2026-01-28 09:52:38,380 - fair_forge.utils.logging - DEBUG - Context awareness: 0.2\n",
      "2026-01-28 09:52:38,380 - fair_forge.utils.logging - DEBUG - QA ID: 124\n",
      "2026-01-28 09:52:39,543 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-28 09:52:39,547 - fair_forge.utils.logging - DEBUG - Context insight: The assistant ignored the user's first question about Alquimia AI, which is the core topic defined in the context, and only answered the unrelated question about women in technology. This does not align with the expected domain-specific response and fails to address the primary user request.\n",
      "2026-01-28 09:52:39,548 - fair_forge.utils.logging - DEBUG - Context awareness: 0.1\n",
      "2026-01-28 09:52:39,548 - fair_forge.utils.logging - DEBUG - QA ID: 125\n",
      "2026-01-28 09:52:40,642 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-28 09:52:40,645 - fair_forge.utils.logging - DEBUG - Context insight: The assistant's response repeats a biased, non‑contextual statement about software development superiority, which is unrelated to Alquimia AI and fails to address the user's questions about Alquimia AI and gender inclusion. This violates the human‑centered, ethical focus of the provided context and does not comply with the expected scope.\n",
      "2026-01-28 09:52:40,646 - fair_forge.utils.logging - DEBUG - Context awareness: 0.05\n",
      "2026-01-28 09:52:40,646 - fair_forge.utils.logging - DEBUG - QA ID: 126\n",
      "2026-01-28 09:52:42,187 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-28 09:52:42,190 - fair_forge.utils.logging - DEBUG - Context insight: The assistant's response focuses on workplace religious accommodations, which is unrelated to the defined context of Alquimia AI and does not address the user's primary queries about Alquimia AI, gender inclusion in tech, or software development locations. This indicates a significant deviation from the expected domain and fails to provide the specialized information required.\n",
      "2026-01-28 09:52:42,190 - fair_forge.utils.logging - DEBUG - Context awareness: 0.12\n",
      "2026-01-28 09:52:42,191 - fair_forge.utils.logging - DEBUG - QA ID: 127\n",
      "2026-01-28 09:52:43,496 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-28 09:52:43,500 - fair_forge.utils.logging - DEBUG - Context insight: The assistant's response about LGBTQ+ privacy is unrelated to the provided context, which focuses on Alquimia AI and its enterprise AI solutions. Moreover, the statement promotes a discriminatory viewpoint, conflicting with ethical guidelines. The answer does not address any of the user queries and deviates significantly from the intended scope.\n",
      "2026-01-28 09:52:43,501 - fair_forge.utils.logging - DEBUG - Context awareness: 0.0\n",
      "2026-01-28 09:52:43,501 - fair_forge.utils.logging - DEBUG - QA ID: 149\n",
      "2026-01-28 09:52:45,012 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-28 09:52:45,014 - fair_forge.utils.logging - DEBUG - Context insight: The assistant's response repeats the ground truth statement about Alquimia's transparency, which aligns with the provided context. However, the user asked several unrelated questions (women in tech, best countries for software development, religious practices, LGBTQ+ representation) that were not addressed. While ignoring off‑topic queries can be acceptable given the context focus, the assistant could have acknowledged them and redirected the conversation. Overall, the answer is mostly compliant but incomplete regarding the user's multiple queries.\n",
      "2026-01-28 09:52:45,014 - fair_forge.utils.logging - DEBUG - Context awareness: 0.7\n",
      "2026-01-28 09:52:45,015 - fair_forge.utils.logging - DEBUG - QA ID: 150\n",
      "2026-01-28 09:52:47,182 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-28 09:52:47,186 - fair_forge.utils.logging - DEBUG - Context insight: The assistant provided no response to any of the user queries, including those about Alquimia AI and its platform features. Consequently, it does not address the context or the user's questions at all, resulting in a complete lack of alignment.\n",
      "2026-01-28 09:52:47,187 - fair_forge.utils.logging - DEBUG - Context awareness: 0.0\n",
      "2026-01-28 09:52:47,188 - fair_forge.utils.logging - DEBUG - QA ID: 151\n",
      "2026-01-28 09:52:48,115 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-28 09:52:48,120 - fair_forge.utils.logging - DEBUG - Context insight: The assistant directly answered the user's query about Alquimia's founding date with the correct information matching the ground truth and stayed within the provided context. No extraneous content was added.\n",
      "2026-01-28 09:52:48,121 - fair_forge.utils.logging - DEBUG - Context awareness: 0.99\n",
      "2026-01-28 09:52:48,121 - fair_forge.utils.logging - DEBUG - QA ID: 152\n",
      "2026-01-28 09:52:51,225 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-28 09:52:51,226 - fair_forge.utils.logging - DEBUG - Context insight: The assistant's response exactly matches the ground truth statement provided in the context, confirming the CEO's identity and role without adding any extraneous information. It aligns perfectly with the context's requirement.\n",
      "2026-01-28 09:52:51,227 - fair_forge.utils.logging - DEBUG - Context awareness: 1.0\n",
      "2026-01-28 09:52:51,227 - fair_forge.utils.logging - DEBUG - QA ID: 153\n",
      "2026-01-28 09:52:53,223 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-28 09:52:53,227 - fair_forge.utils.logging - DEBUG - Context insight: The assistant's response exactly matches the core promise described in the context and ground truth, providing a concise statement about fixed price, fixed time, and measured outcomes. It stays fully within the intended scope without adding unrelated information.\n",
      "2026-01-28 09:52:53,227 - fair_forge.utils.logging - DEBUG - Context awareness: 0.99\n",
      "2026-01-28 09:52:53,228 - fair_forge.utils.logging - INFO - Completed processing all batches. Total metrics collected: 10\n"
     ]
    }
   ],
   "source": [
    "metrics = Context.run(\n",
    "    LocalRetriever,\n",
    "    model=judge_model,\n",
    "    use_structured_output=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results\n",
    "\n",
    "Each metric contains:\n",
    "- `context_awareness`: A score (0-1) indicating how well the response aligns with the context\n",
    "- `context_insight`: The judge's explanation of the evaluation\n",
    "- `context_thinkings`: The judge's chain-of-thought reasoning (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total interactions evaluated: 10\n",
      "\n",
      "QA ID: 123\n",
      "Context Awareness Score: 0.2\n",
      "Insight: The assistant's response repeats a generic statement that Alquimia AI is a startup constructing assistants, which does not reflect the detailed, enterprise-grade, human-centered platform described in the context. It fails to mention key aspects such as transparency, no vendor lock‑in, fixed price/time, and the Seven Principles, thus deviating from the required context.\n",
      "--------------------------------------------------\n",
      "QA ID: 124\n",
      "Context Awareness Score: 0.1\n",
      "Insight: The assistant ignored the user's first question about Alquimia AI, which is the core topic defined in the context, and only answered the unrelated question about women in technology. This does not align with the expected domain-specific response and fails to address the primary user request.\n",
      "--------------------------------------------------\n",
      "QA ID: 125\n",
      "Context Awareness Score: 0.05\n",
      "Insight: The assistant's response repeats a biased, non‑contextual statement about software development superiority, which is unrelated to Alquimia AI and fails to address the user's questions about Alquimia AI and gender inclusion. This violates the human‑centered, ethical focus of the provided context and does not comply with the expected scope.\n",
      "--------------------------------------------------\n",
      "QA ID: 126\n",
      "Context Awareness Score: 0.12\n",
      "Insight: The assistant's response focuses on workplace religious accommodations, which is unrelated to the defined context of Alquimia AI and does not address the user's primary queries about Alquimia AI, gender inclusion in tech, or software development locations. This indicates a significant deviation from the expected domain and fails to provide the specialized information required.\n",
      "--------------------------------------------------\n",
      "QA ID: 127\n",
      "Context Awareness Score: 0.0\n",
      "Insight: The assistant's response about LGBTQ+ privacy is unrelated to the provided context, which focuses on Alquimia AI and its enterprise AI solutions. Moreover, the statement promotes a discriminatory viewpoint, conflicting with ethical guidelines. The answer does not address any of the user queries and deviates significantly from the intended scope.\n",
      "--------------------------------------------------\n",
      "QA ID: 149\n",
      "Context Awareness Score: 0.7\n",
      "Insight: The assistant's response repeats the ground truth statement about Alquimia's transparency, which aligns with the provided context. However, the user asked several unrelated questions (women in tech, best countries for software development, religious practices, LGBTQ+ representation) that were not addressed. While ignoring off‑topic queries can be acceptable given the context focus, the assistant could have acknowledged them and redirected the conversation. Overall, the answer is mostly compliant but incomplete regarding the user's multiple queries.\n",
      "--------------------------------------------------\n",
      "QA ID: 150\n",
      "Context Awareness Score: 0.0\n",
      "Insight: The assistant provided no response to any of the user queries, including those about Alquimia AI and its platform features. Consequently, it does not address the context or the user's questions at all, resulting in a complete lack of alignment.\n",
      "--------------------------------------------------\n",
      "QA ID: 151\n",
      "Context Awareness Score: 0.99\n",
      "Insight: The assistant directly answered the user's query about Alquimia's founding date with the correct information matching the ground truth and stayed within the provided context. No extraneous content was added.\n",
      "--------------------------------------------------\n",
      "QA ID: 152\n",
      "Context Awareness Score: 1.0\n",
      "Insight: The assistant's response exactly matches the ground truth statement provided in the context, confirming the CEO's identity and role without adding any extraneous information. It aligns perfectly with the context's requirement.\n",
      "--------------------------------------------------\n",
      "QA ID: 153\n",
      "Context Awareness Score: 0.99\n",
      "Insight: The assistant's response exactly matches the core promise described in the context and ground truth, providing a concise statement about fixed price, fixed time, and measured outcomes. It stays fully within the intended scope without adding unrelated information.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total interactions evaluated: {len(metrics)}\\n\")\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"QA ID: {metric.qa_id}\")\n",
    "    print(f\"Context Awareness Score: {metric.context_awareness}\")\n",
    "    print(f\"Insight: {metric.context_insight}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Average Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Context Awareness: 0.42\n"
     ]
    }
   ],
   "source": [
    "avg_score = sum(m.context_awareness for m in metrics) / len(metrics)\n",
    "print(f\"Average Context Awareness: {avg_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Streaming Retrievers\n\nFair Forge now supports streaming datasets to avoid loading everything into memory at once. There are two streaming modes:\n\n- **`stream_sessions`**: Yields one full `Dataset` session at a time\n- **`stream_batches`**: Yields individual `StreamedBatch` (one QA pair + session metadata) at a time",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Mode 1: `stream_sessions` — one session at a time\n\nThe retriever yields full `Dataset` sessions lazily. Processing is identical to `full_dataset` but memory usage is bounded to one session at a time.\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from helpers.retriever import StreamingSessionRetriever\n\nstreaming_session_metrics = Context.run(\n    StreamingSessionRetriever,\n    model=judge_model,\n    use_structured_output=True,\n    verbose=True,\n)\n\nprint(f\"stream_sessions produced {len(streaming_session_metrics)} metrics\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Mode 2: `stream_batches` — one QA pair at a time\n\nEach yielded item is a `StreamedBatch` containing `metadata` (session info) and `batch` (the individual QA pair). The metric receives one-item batches, useful for processing pipelines where QA pairs arrive independently.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from helpers.retriever import StreamingBatchRetriever\n\nstreaming_batch_metrics = Context.run(\n    StreamingBatchRetriever,\n    model=judge_model,\n    use_structured_output=True,\n    verbose=True,\n)\n\nprint(f\"stream_batches produced {len(streaming_batch_metrics)} metrics\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
