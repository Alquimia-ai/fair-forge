{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Attribution Analysis with Fair Forge\n",
    "\n",
    "This notebook demonstrates how to use Fair Forge's explainability module to compute and visualize token attributions for language model responses.\n",
    "\n",
    "Token attribution helps answer: **\"Which parts of the input influenced the model's output the most?\"**\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Install Fair Forge with explainability support:\n",
    "```bash\n",
    "pip install alquimia-fair-forge[explainability]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment if needed)\n",
    "# %pip install alquimia-fair-forge[explainability] transformers torch -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup: Load Model and Tokenizer\n",
    "\n",
    "We'll use a small model for demonstration. The explainability module works with any HuggingFace causal language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Disable autocast for compatibility with attribution methods\n",
    "torch.set_autocast_enabled(False)\n",
    "\n",
    "# Load a small model (Qwen3-0.6B for this example)\n",
    "repo_id = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(repo_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    repo_id,\n",
    "    torch_dtype=torch.float16  # Important: use float16 for attribution methods\n",
    ")\n",
    "\n",
    "print(f\"Loaded model: {repo_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Fair Forge Explainability Module\n",
    "\n",
    "The module uses class-based attribution methods for extensibility. You pass method classes (like `Lime`, `Saliency`) directly to the explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fair_forge.explainability import (\n",
    "    AttributionExplainer,\n",
    "    Granularity,\n",
    "    # Method classes\n",
    "    Lime,\n",
    "    Occlusion,\n",
    "    Saliency,\n",
    "    IntegratedGradients,\n",
    "    compute_attributions,\n",
    ")\n",
    "\n",
    "# Create an explainer instance\n",
    "explainer = AttributionExplainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    default_method=Lime,            # Pass the class directly\n",
    "    default_granularity=Granularity.WORD,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"Explainer created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Format Your Prompt\n",
    "\n",
    "**Important:** You are responsible for formatting prompts according to your model's requirements. This keeps the explainability module focused on attribution computation and avoids coupling with specific LLM prompt formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the conversation\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Answer concisely with 3 bullet points.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Explain Albert Einstein's theory of relativity\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Format the prompt using your tokenizer (model-specific)\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "print(\"Formatted prompt:\")\n",
    "print(prompt[:500] + \"...\" if len(prompt) > 500 else prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute Attributions\n",
    "\n",
    "Now compute attributions for a target response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model's actual response (target text to explain)\n",
    "target = \"\"\"\n",
    "- Einstein proposed that time and space are not absolute but relative.\n",
    "- He introduced spacetime curvature, explaining gravity as distortion.\n",
    "- His equations revolutionized physics and led to E=mc^2.\n",
    "\"\"\"\n",
    "\n",
    "# Compute attributions\n",
    "result = explainer.explain(\n",
    "    prompt=prompt,\n",
    "    target=target,\n",
    "    method=Lime,  # Pass the class directly\n",
    ")\n",
    "\n",
    "print(f\"Computed {len(result.attributions)} attributions\")\n",
    "print(f\"Method: {result.method.value}\")\n",
    "print(f\"Granularity: {result.granularity.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Top Contributing Tokens/Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 10 most important tokens\n",
    "top_10 = result.get_top_k(10)\n",
    "\n",
    "print(\"Top 10 Most Important Words/Tokens:\")\n",
    "print(\"-\" * 40)\n",
    "for i, attr in enumerate(top_10, 1):\n",
    "    norm = f\"{attr.normalized_score:.4f}\" if attr.normalized_score else \"N/A\"\n",
    "    print(f\"{i:2}. '{attr.text:15}' | score: {attr.score:+.4f} | normalized: {norm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Attributions\n",
    "\n",
    "The explainer can display an interactive visualization of the attributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the attribution visualization\n",
    "explainer.visualize(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare Different Attribution Methods\n",
    "\n",
    "Fair Forge supports multiple attribution methods as classes. Let's compare a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simpler example for faster computation\n",
    "simple_messages = [{\"role\": \"user\", \"content\": \"What is the capital of France?\"}]\n",
    "simple_prompt = tokenizer.apply_chat_template(simple_messages, tokenize=False, add_generation_prompt=True)\n",
    "simple_target = \"The capital of France is Paris.\"\n",
    "\n",
    "# Compare different methods (pass the class directly)\n",
    "methods_to_compare = [Lime, Occlusion]\n",
    "\n",
    "for method_class in methods_to_compare:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Method: {method_class.name.upper()}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    result = explainer.explain(\n",
    "        prompt=simple_prompt,\n",
    "        target=simple_target,\n",
    "        method=method_class,\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTop 5 contributing words:\")\n",
    "    for attr in result.get_top_k(5):\n",
    "        print(f\"  '{attr.text}': {attr.score:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Batch Processing\n",
    "\n",
    "Process multiple prompt/target pairs at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple prompt/target pairs (prompts should be pre-formatted)\n",
    "qa_pairs = [\n",
    "    (\n",
    "        tokenizer.apply_chat_template(\n",
    "            [{\"role\": \"user\", \"content\": \"What is machine learning?\"}],\n",
    "            tokenize=False, add_generation_prompt=True\n",
    "        ),\n",
    "        \"Machine learning is a subset of AI that enables systems to learn from data.\"\n",
    "    ),\n",
    "    (\n",
    "        tokenizer.apply_chat_template(\n",
    "            [{\"role\": \"user\", \"content\": \"What is deep learning?\"}],\n",
    "            tokenize=False, add_generation_prompt=True\n",
    "        ),\n",
    "        \"Deep learning uses neural networks with many layers to process complex patterns.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Compute attributions for all pairs\n",
    "batch_results = explainer.explain_batch(qa_pairs)\n",
    "\n",
    "print(f\"Processed {len(batch_results)} items\")\n",
    "print(f\"Total compute time: {batch_results.total_compute_time_seconds:.2f}s\")\n",
    "\n",
    "# Show top words for each\n",
    "for i, result in enumerate(batch_results):\n",
    "    print(f\"\\nQ&A #{i+1}:\")\n",
    "    print(f\"  Top 3 words: {[attr.text for attr in result.get_top_k(3)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Using the Convenience Function\n",
    "\n",
    "For one-off attributions, use the `compute_attributions` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format prompt\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"content\": \"Why is the sky blue?\"}],\n",
    "    tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# Quick one-liner for attribution computation\n",
    "quick_result = compute_attributions(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    target=\"The sky appears blue due to Rayleigh scattering of sunlight.\",\n",
    "    method=Lime,\n",
    "    granularity=Granularity.WORD,\n",
    ")\n",
    "\n",
    "print(\"Top 5 contributing words:\")\n",
    "for attr in quick_result.get_top_k(5):\n",
    "    print(f\"  '{attr.text}': {attr.score:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Results for Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to dictionary format\n",
    "viz_data = quick_result.to_dict_for_visualization()\n",
    "print(\"Visualization data structure:\")\n",
    "print(f\"  tokens: {viz_data['tokens'][:5]}...\")\n",
    "print(f\"  scores: {viz_data['scores'][:5]}...\")\n",
    "\n",
    "# Export full result as JSON-compatible dict\n",
    "result_dict = quick_result.model_dump()\n",
    "print(f\"\\nFull result keys: {list(result_dict.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Setup**: Loading a model and creating an `AttributionExplainer`\n",
    "2. **Prompt formatting**: Using `tokenizer.apply_chat_template()` (user responsibility)\n",
    "3. **Single attributions**: Using `explainer.explain()` with pre-formatted prompts\n",
    "4. **Top-K analysis**: Finding the most important tokens with `get_top_k()`\n",
    "5. **Visualization**: Interactive display with `explainer.visualize()`\n",
    "6. **Method comparison**: Comparing `Lime`, `Occlusion`, and other methods (class-based)\n",
    "7. **Batch processing**: Processing multiple items with `explain_batch()`\n",
    "8. **Convenience function**: Quick one-off attribution with `compute_attributions()`\n",
    "9. **Export**: Getting data for further analysis\n",
    "\n",
    "### Available Attribution Method Classes\n",
    "\n",
    "**Gradient-based** (faster, require differentiable models):\n",
    "- `Saliency`, `IntegratedGradients`, `GradientShap`, `SmoothGrad`, `SquareGrad`, `VarGrad`, `InputXGradient`\n",
    "\n",
    "**Perturbation-based** (model-agnostic, more robust):\n",
    "- `Lime`, `KernelShap`, `Occlusion`, `Sobol`\n",
    "\n",
    "### Granularity Options\n",
    "- `Granularity.TOKEN`: Individual tokens (finest granularity)\n",
    "- `Granularity.WORD`: Word-level (recommended for interpretability)\n",
    "- `Granularity.SENTENCE`: Sentence-level (coarsest granularity)\n",
    "\n",
    "### Key Design Decisions\n",
    "- **Pre-formatted prompts**: Users format prompts according to their model's requirements\n",
    "- **Class-based methods**: Attribution methods are classes for extensibility\n",
    "- **Parser interface**: Custom parsers can be implemented for different attribution libraries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
