{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aff02e77-ce1c-4b99-b3dd-c8ed2db1ad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install dist/alquimia_fair_forge-0.0.1.tar.gz -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad4a3e22-58e8-4953-8abf-24bfd9791e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexfiorenza/Documents/software_development/projects/alquimia/fair-forge/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from helpers.retriever import LocalRetriever\n",
    "from fair_forge.metrics import Bias\n",
    "from pydantic import SecretStr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "guardian_api_key = SecretStr(getpass(\"Please enter your Guardian LLM API key: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELASTIC_URL = os.environ.get('ELASTIC_URL')\n",
    "ELASTIC_AUTH = [os.environ.get('ELASTIC_AUTH_USER'), os.environ.get('ELASTIC_AUTH_PASSWORD')]\n",
    "dataset = os.environ.get(\"dataset\", \"asb\")\n",
    "bias_index = f\"{dataset}-bias\"\n",
    "guardian_temperature = 0.5\n",
    "max_tokens = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRANITE\n",
    "GUARDIAN_URL = os.environ.get(\"GUARDIAN_URL\",\"https://runtime.apps.hostmydemo.online\")\n",
    "GUARDIAN_MODEL_NAME = os.environ.get(\"GUARDIAN_MODEL_NAME\",\"ibm-granite/granite-guardian-3.1-2b\")\n",
    "GUARDIAN_API_KEY = guardian_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LLAMA GUARD\n",
    "GUARDIAN_URL = \"https://api.groq.com/openai\"\n",
    "GUARDIAN_MODEL_NAME = \"meta-llama/Llama-Guard-4-12B\"\n",
    "hf_token = SecretStr(getpass(\"Please enter your Hugging Face token: \"))\n",
    "os.environ[\"HF_TOKEN\"] = hf_token.get_secret_value()\n",
    "GUARDIAN_API_KEY = guardian_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fair_forge.guardians import IBMGranite,LLamaGuard\n",
    "from fair_forge.guardians.llms.providers import OpenAIGuardianProvider\n",
    "from fair_forge.schemas import GuardianLLMConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 12:05:28,129 - fair_forge - INFO - Loaded dataset with 1 batches\n",
      "2025-05-23 12:05:28,841 - fair_forge - INFO - Starting to process dataset\n",
      "2025-05-23 12:05:28,841 - fair_forge - INFO - Processing batch 1/1\n",
      "2025-05-23 12:05:28,841 - fair_forge - INFO - Session ID: 123, Assistant ID: my_assistant\n",
      "2025-05-23 12:05:28,842 - fair_forge - INFO - QA ID: 123\n",
      "2025-05-23 12:05:31,812 - fair_forge - INFO - QA ID: 124\n",
      "2025-05-23 12:05:34,258 - fair_forge - INFO - QA ID: 125\n",
      "2025-05-23 12:05:36,542 - fair_forge - INFO - QA ID: 126\n",
      "2025-05-23 12:05:39,289 - fair_forge - INFO - QA ID: 127\n",
      "2025-05-23 12:05:41,849 - fair_forge - INFO - QA ID: 128\n",
      "2025-05-23 12:05:44,377 - fair_forge - INFO - QA ID: 129\n",
      "2025-05-23 12:05:46,812 - fair_forge - INFO - QA ID: 130\n",
      "2025-05-23 12:05:49,534 - fair_forge - INFO - [gender]: Clopper-Pearson Confidence Interval: [0.34462318685401877 - 0.625 - 0.8531450676486562]\n",
      "2025-05-23 12:05:49,536 - fair_forge - INFO - [race]: Clopper-Pearson Confidence Interval: [0.46178460348232164 - 0.75 - 0.9313739527471758]\n",
      "2025-05-23 12:05:49,538 - fair_forge - INFO - [religion]: Clopper-Pearson Confidence Interval: [0.23966182889945448 - 0.5 - 0.7603381711005455]\n",
      "2025-05-23 12:05:49,539 - fair_forge - INFO - [nationality]: Clopper-Pearson Confidence Interval: [0.23966182889945448 - 0.5 - 0.7603381711005455]\n",
      "2025-05-23 12:05:49,540 - fair_forge - INFO - [sexual_orientation]: Clopper-Pearson Confidence Interval: [0.06862604725282417 - 0.25 - 0.5382153965176784]\n",
      "2025-05-23 12:05:49,541 - fair_forge - INFO - Completed processing all batches. Total metrics collected: 0\n"
     ]
    }
   ],
   "source": [
    "metrics= Bias.run(\n",
    "    LocalRetriever,\n",
    "    guardian = LLamaGuard,\n",
    "    confidence_level= 0.90,\n",
    "    config = GuardianLLMConfig(\n",
    "        model= GUARDIAN_MODEL_NAME,\n",
    "        api_key= GUARDIAN_API_KEY.get_secret_value(),\n",
    "        url=GUARDIAN_URL,\n",
    "        temperature=guardian_temperature,\n",
    "        provider=OpenAIGuardianProvider\n",
    "    ),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\n",
    "    ELASTIC_URL,\n",
    "    basic_auth=tuple(ELASTIC_AUTH),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_index(index_name: str, mapping: dict):\n",
    "    if es.indices.exists(index=index_name):\n",
    "        es.indices.delete(index=index_name)\n",
    "        print(f\"Index '{index_name}' deleted.\")\n",
    "    es.indices.create(index=index_name, body=mapping)\n",
    "    print(f\"Index '{index_name}' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_guard_metrics(metrics):\n",
    "    flattened = []\n",
    "    for metric in metrics:\n",
    "        for risk in metric.risks:\n",
    "            flattened.append(\n",
    "                {\n",
    "                    \"session_id\": metric.session_id,\n",
    "                    \"qa_id\": metric.qa_id,\n",
    "                    \"assistant_id\": metric.assistant_id,\n",
    "                    'bias_guard_is_risk': risk.is_risk,\n",
    "                    'bias_guard_type': risk.risk_type,\n",
    "                    'bias_guard_probability': risk.probability\n",
    "                }\n",
    "            )\n",
    "    return flattened\n",
    "flattened = flatten_guard_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_bias = {\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"session_id\": {\"type\": \"keyword\"},\n",
    "      \"bias_guard_is_risk\": {\"type\": \"boolean\"},\n",
    "      \"bias_guard_type\": {\"type\": \"text\"},\n",
    "      \"bias_guard_probability\": {\"type\": \"float\"},\n",
    "      \"assistant_id\": {\"type\": \"keyword\"},\n",
    "      \"qa_id\": {\"type\": \"keyword\"},\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreate_index(bias_index, mapping_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for flatten in flattened:\n",
    "    docs.append({\n",
    "            \"_index\": bias_index,\n",
    "            \"_source\": flatten\n",
    "    })\n",
    "\n",
    "helpers.bulk(es, docs)\n",
    "print(f\"Indexed {len(docs)} documents.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
