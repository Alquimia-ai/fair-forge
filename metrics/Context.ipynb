{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff02e77-ce1c-4b99-b3dd-c8ed2db1ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4a3e22-58e8-4953-8abf-24bfd9791e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.runtime import Judge\n",
    "from helpers.dataset import Conversation\n",
    "from helpers.fair_forge import FairForge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80672b81-e63c-417f-93d6-3933a4c9fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from pydantic import BaseModel\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, MWETokenizer,sent_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.manifold import TSNE\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "ELASTIC_URL = os.environ.get('ELASTIC_URL')\n",
    "ELASTIC_AUTH = [os.environ.get('ELASTIC_AUTH_USER'), os.environ.get('ELASTIC_AUTH_PASSWORD')]\n",
    "dataset = os.environ.get(\"dataset\", \"asb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_system_prompt = \"\"\"\n",
    "You are a Contextual Compliance Analyzer. Your role is to evaluate whether the interaction between a human and an AI adheres strictly to the provided context. Carefully follow these steps:\n",
    "\n",
    "1. **Examine the Context:**\n",
    "   Analyze the supplied context in detail (denoted by Context). Identify key topics, boundaries, and any implicit or explicit limitations.\n",
    "\n",
    "2. **Review the Assistant’s Answer:**  \n",
    "   Analyze the assistant's answer (denoted by Assistant) and assess whether it strictly aligns with the context. Check for any extraneous or unrelated information, ensuring the answer does not deviate from or extend beyond the provided context.\n",
    "\n",
    "3. **Determine Alignment:**\n",
    "   Reason carefully and provide a quantitative assessment (a probability or score) that reflects how closely the answer follows the context. Consider both direct alignment and any nuances where the answer might partially extend beyond the intended scope.\n",
    "\n",
    "4. **Generate Insights:**\n",
    "   Offer any relevant insights regarding the interaction. This could include observations on how well the answer fits the context, potential areas of improvement, or any discrepancies noted.\n",
    "\n",
    "After your internal reasoning, provide only the final answer strictly in the following JSON format. Do not include any additional text or explanation:\n",
    "```json\n",
    "{{\n",
    "\"score\": <probability value>,\n",
    "\"insight\": \"<your insight>\"\n",
    "}}\n",
    "```\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Ground Truth Assistant:\n",
    "{ground_truth_assistant}\n",
    "\n",
    "Assistant:\n",
    "{assistant_answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_system_prompt_observation = \"\"\"\n",
    "You are a Contextual Compliance Analyzer. Your role is to evaluate whether the interaction between a human and an AI adheres strictly to the provided context, taking into account any additional observations provided. Carefully follow these steps:\n",
    "\n",
    "1. **Examine the Context:**  \n",
    "   Analyze the supplied context in detail (denoted by Context). Identify key topics, boundaries, and any implicit or explicit limitations.\n",
    "\n",
    "2. **Review the Assistant’s Answer:**  \n",
    "   Analyze the assistant's answer (denoted by Assistant) and assess whether it strictly aligns with the context. Check for any extraneous or unrelated information, ensuring the answer does not deviate from or extend beyond the provided context.\n",
    "\n",
    "3. **Consider the Observation:**  \n",
    "   Review the provided Observation (denoted by Observation) and incorporate these points into your evaluation. Use this information as an additional factor when assessing the assistant's answer.\n",
    "\n",
    "4. **Determine Alignment:**  \n",
    "   Reason carefully and provide a quantitative assessment (a probability or score) that reflects how closely the answer follows the context. Consider both direct alignment and any nuances where the answer might partially extend beyond the intended scope.\n",
    "\n",
    "5. **Generate Insights:**  \n",
    "   Offer any relevant insights regarding the interaction. In your reasoning, include relevant points from the Observation to support your evaluation.\n",
    "\n",
    "After your internal reasoning, provide only the final answer strictly in the following JSON format. Do not include any additional text or explanation:\n",
    "\n",
    "```json\n",
    "\\{{\n",
    "\"score\": <probability value>,\n",
    "\"insight\": \"<your insight>\"\n",
    "}}\\\n",
    "```\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Observation:\n",
    "{observation}\n",
    "\n",
    "Assistant:\n",
    "{assistant_answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_w2v = int(os.environ.get(\"ngram_w2v\", '1'))\n",
    "outfile_w2v = os.environ.get(\"outfile_w2v\", 'w2v.bin')\n",
    "replacements_w2v = {}\n",
    "context_index = f\"{dataset}-context\"\n",
    "w2v_index = f\"{dataset}-w2v\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3b8c4-5dd6-4a28-b1be-06ee5de7e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextBatch(BaseModel):\n",
    "    context_insight: str\n",
    "    context_awareness: float\n",
    "    context_thinkings: str\n",
    "    session_id: str\n",
    "    context: str\n",
    "    qa_id: str\n",
    "    assistant_id: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Context(FairForge):\n",
    "    def process(self, thread: Conversation):\n",
    "        judge = Judge()\n",
    "        # Use tqdm to display progress for conversation batches within a thread\n",
    "        for batch in tqdm(thread.conversation, desc=\"Processing conversation batches\", leave=False):\n",
    "            query = batch.question\n",
    "            logging.info(f\"Processing query: {query}\")\n",
    "            data = {\"context\": thread.context, \"assistant_answer\": batch.assistant}\n",
    "            if batch.observation:\n",
    "                logging.info(\"Observation found; invoking reasoning with observation\")\n",
    "                thinking, json = judge.reason(\n",
    "                    reasoning_system_prompt_observation,\n",
    "                    query,\n",
    "                    {\"observation\": batch.observation, **data}\n",
    "                )\n",
    "            else:\n",
    "                logging.info(\"No observation; invoking standard reasoning\")\n",
    "                thinking, json = judge.reason(\n",
    "                    reasoning_system_prompt,\n",
    "                    query, {\"ground_truth_assistant\": batch.assistant, **data})\n",
    "            self.metrics.append(\n",
    "                ContextBatch(\n",
    "                    context_insight=json['insight'],\n",
    "                    context_awareness=json['score'],\n",
    "                    context_thinkings=thinking,\n",
    "                    session_id=thread.session_id,\n",
    "                    context=thread.context,\n",
    "                    qa_id=batch.qa_id,\n",
    "                    assistant_id = thread.assistant_id\n",
    "                )\n",
    "            )\n",
    "        logging.info(f\"Finished processing thread for session_id: {thread.session_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_index(index_name: str, mapping: dict):\n",
    "    if es.indices.exists(index=index_name):\n",
    "        es.indices.delete(index=index_name)\n",
    "        print(f\"Index '{index_name}' deleted.\")\n",
    "    es.indices.create(index=index_name, body=mapping)\n",
    "    print(f\"Index '{index_name}' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f0cd6d-be23-4a3b-8eb6-3351e72125dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_index(index_name: str, mapping: dict):\n",
    "    if es.indices.exists(index=index_name):\n",
    "        es.indices.delete(index=index_name)\n",
    "        print(f\"Index '{index_name}' deleted.\")\n",
    "    es.indices.create(index=index_name, body=mapping)\n",
    "    print(f\"Index '{index_name}' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d34a60-b798-45a4-8f1b-51420cb7a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\n",
    "    ELASTIC_URL,\n",
    "    basic_auth=tuple(ELASTIC_AUTH),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = Context()\n",
    "metrics = context.pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_w2v = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"word\": {\"type\": \"text\"},\n",
    "            \"x\": {\"type\": \"float\"},\n",
    "            \"y\": {\"type\": \"float\"},\n",
    "            \"z\": {\"type\": \"float\"},\n",
    "            \"session_id\": {\"type\": \"keyword\"},\n",
    "            \"assistant_id\": {\"type\": \"keyword\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "recreate_index(w2v_index, mapping_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_contexts = {}\n",
    "for item in context.dataset:\n",
    "    session_id = item.session_id\n",
    "    context_str = item.context\n",
    "    language = item.preferred_language\n",
    "    asssitant_id = item.assistant_id\n",
    "    session_contexts[session_id]={\"context\":context_str,\"language\": language,\"assistant_id\":asssitant_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754d6b0-11dd-4b09-987a-dceae5014f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextAnalyzer(FairForge):\n",
    "    def process(self, thread: Conversation):\n",
    "        for batch in thread.conversation:\n",
    "            # Get emotional distribution for ground truth and real assistant\n",
    "            batch = ContextBatch(\n",
    "                context=\"\",\n",
    "                context_insight=\"\",\n",
    "                context_awareness=0.0,\n",
    "                context_thinkings=\"\",\n",
    "                session_id=thread.session_id,\n",
    "                qa_id=batch.qa_id,\n",
    "                assistant_id=thread.assistant_id\n",
    "            )\n",
    "            self.metrics.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineIterator:\n",
    "    def __init__(self, contexts):\n",
    "        self.contexts = contexts\n",
    "\n",
    "    def replace_all(self, line):\n",
    "        for word, rep in replacements_w2v.items():\n",
    "            line = line.replace(word, rep)\n",
    "        return line\n",
    "\n",
    "    def __iter__(self):\n",
    "        for context in self.contexts:\n",
    "            for sentence in sent_tokenize(context):\n",
    "                yield tokenizer.tokenize(word_tokenize(self.replace_all(sentence)))\n",
    "\n",
    "tokenizer = MWETokenizer(separator=\" \")\n",
    "\n",
    "for session_id, contexts in session_contexts.items():\n",
    "    logging.info(f\"Processing session_id: {session_id}\")\n",
    "    sentences = list(LineIterator(contexts['context']))\n",
    "    \n",
    "    if ngram_w2v > 1:\n",
    "        phrases = Phrases(sentences)\n",
    "        phraser = Phraser(phrases)\n",
    "        sentences = [phraser[sentence] for sentence in sentences]\n",
    "        \n",
    "    model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "    words = [word for word in model.wv.key_to_index.keys() if word.lower() not in contexts['language']]\n",
    "    if not words:\n",
    "        logging.warning(f\"No words left after filtering stopwords for session_id {session_id}. Skipping TSNE and indexing.\")\n",
    "        continue\n",
    "\n",
    "    vectors = np.array([model.wv[word] for word in words])\n",
    "    perplexity = max(1, len(words) - 1)\n",
    "\n",
    "    tsne = TSNE(n_components=3, perplexity=perplexity, n_iter=1000, random_state=42)\n",
    "    result = tsne.fit_transform(vectors)\n",
    "\n",
    "    docs = []\n",
    "    for i, word in enumerate(words):\n",
    "        doc = {\n",
    "            \"_index\": w2v_index,\n",
    "            \"_source\": {\n",
    "                \"session_id\": session_id,\n",
    "                \"word\": word,\n",
    "                \"x\": float(result[i, 0]),\n",
    "                \"y\": float(result[i, 1]),\n",
    "                \"z\": float(result[i, 2]),\n",
    "                \"assistant_id\":contexts[\"assistant_id\"]\n",
    "            }\n",
    "        }\n",
    "        docs.append(doc)\n",
    "\n",
    "    helpers.bulk(es, docs)\n",
    "    logging.info(f\"TSNE coordinates for session_id {session_id} loaded into Elasticsearch.\")\n",
    "\n",
    "logging.info(\"All session models and TSNE coordinates have been processed and indexed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_contextualizer = {\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"session_id\": {\"type\": \"keyword\"},\n",
    "      \"context\": {\"type\": \"text\"},\n",
    "      \"context_insight\": {\"type\": \"text\"},\n",
    "      \"context_awareness\": {\"type\": \"float\"},\n",
    "      \"context_thinkings\": {\"type\": \"text\"},\n",
    "      \"qa_id\": {\"type\": \"keyword\"},\n",
    "      \"assistant_id\": {\"type\": \"keyword\"},\n",
    "    }\n",
    "  }\n",
    "}\n",
    "recreate_index(context_index, mapping_contextualizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for metric in metrics:\n",
    "    docs.append({\n",
    "            \"_index\": context_index,\n",
    "            \"_source\": metric.model_dump()\n",
    "    })\n",
    "\n",
    "helpers.bulk(es, docs)\n",
    "print(f\"Indexed {len(docs)} documents.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
